{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 2: Timing, Numpy, Plotting\n",
    "\n",
    "The previous exercise sheet introduced several methods for classification: decision trees, nearest neighbors, and nearest means. Of those, the one that could learn from the data, and that also offered enough complexity to produce an accurate decision function was k-nearest neighbors. However, nearest neighbors can be slow when implemented in pure Python (i.e. with loops). This is especially the case when the number of data points or input dimensions is large.\n",
    "\n",
    "In this exercise sheet, we will speed up nearest neighbors by utilizing `numpy`, `scipy` and `scikit-learn` (sklearn) packages. Your task will be to **replace list-based operations by vector-based operations** using numpy arrays. The speed and correctness of the implementations will then be tested. In particular, performance graphs will be drawn using the library `matplotlib`.\n",
    "\n",
    "Make sure to have installed all the required packages (numpy, scipy, sklearn, matplotlib). For this you can use `conda install <package>` or `pip install <package>`.\n",
    "\n",
    "e.g. (-U will upgrade the package version if already installed)\n",
    "\n",
    "`pip install -U numpy scipy scikit-learn matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install numpy, scipy, scikit-learn and matplotlib using the instructions above.\n"
     ]
    }
   ],
   "source": [
    "def get_module_version_tuple(module):\n",
    "    return tuple([int(num) for num in module.__version__.split(\".\")])\n",
    "\n",
    "try:\n",
    "    import numpy\n",
    "    import scipy\n",
    "    import sklearn\n",
    "    import matplotlib\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"Please install numpy, scipy, scikit-learn and matplotlib using the instructions above.\"\n",
    "    )\n",
    "else:\n",
    "    numpy_version = get_module_version_tuple(numpy)\n",
    "    scipy_version = get_module_version_tuple(scipy)\n",
    "    sklearn_version = get_module_version_tuple(sklearn)\n",
    "    matplotlib_version = get_module_version_tuple(matplotlib)\n",
    "    if numpy_version >= (1, 24, 0):\n",
    "        print(f\"NumPy version ok! {numpy_version}\")\n",
    "    else:\n",
    "        print(f\"Your NumPy version is too old!!! {numpy_version}\")\n",
    "\n",
    "    if scipy_version >= (1, 11, 0):\n",
    "        print(f\"SciPy version ok! {scipy_version}\")\n",
    "    else:\n",
    "        print(f\"Your SciPy version is too old!!! {scipy_version}\")\n",
    "\n",
    "    if sklearn_version >= (1, 3, 0):\n",
    "        print(f\"sklearn version ok! {sklearn_version}\")\n",
    "    else:\n",
    "        print(f\"Your sklearn version is too old!!! {sklearn_version}\")\n",
    "\n",
    "    if matplotlib_version >= (3, 6, 0):\n",
    "        print(f\"matplotlib version ok! {matplotlib_version}\")\n",
    "    else:\n",
    "        print(f\"Your matplotlib version is too old!!! {sklearn_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "To each task tests are provided. You can use these tests to practice test driven development (TDD), but please note that using them will likely make the tasks easier.\n",
    "Please also not that the tests may not be exhaustive, i.e. even when passing all tests, your solution can still be imperfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is for setup the testing. Please execute.\n",
    "\n",
    "# Use unittest asserts\n",
    "import unittest\n",
    "t = unittest.TestCase()\n",
    "from pprint import pprint\n",
    "from minified import max_allowed_loops, no_imports, no_loops_allowed\n",
    "\n",
    "# For typing\n",
    "from typing import Optional, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm Ups\n",
    "\n",
    "Before starting the homework sheet we recommend you finish these warm-up tasks. They should help you get familiar with NumPy concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)  # seed for reproducibility\n",
    "\n",
    "x1 = np.random.randint(10, size=6)  # random one-dimensional integer array\n",
    "x2 = np.random.randint(10, size=(5, 4))  # random two-dimensional integer array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of an Array\n",
    "\n",
    "Write a function that returns the number of rows and the number of columns of an array. If the array is one-dimensional, the function should assume that it is a row and the columns should be 0.\n",
    "\n",
    "* Use the attribute `.shape` that every numpy array has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_shape(array: np.ndarray) -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Returns the number of rows and the number of columns of an array.\n",
    "\n",
    "    Args:\n",
    "        array: A numpy array\n",
    "\n",
    "    Returns:\n",
    "        tuple: The number of rows and the number of columns of the array\n",
    "    \"\"\"\n",
    "    if array.ndim==1:\n",
    "        number_of_rows=array.shape[0]\n",
    "        number_of_columns=0\n",
    "    else:\n",
    "        number_of_rows, number_of_columns=array.shape\n",
    "\n",
    "    return number_of_rows, number_of_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test array_shape function\n",
    "def test_array_shape():\n",
    "    x1 = np.random.randint(10, size=6) \n",
    "    x2 = np.random.randint(10, size=(5, 4)) \n",
    "    \n",
    "    x1_number_of_rows, x1_number_of_columns = array_shape(x1)\n",
    "    x2_number_of_rows, x2_number_of_columns = array_shape(x2)\n",
    "\n",
    "    t.assertEqual(x1_number_of_rows, 6)\n",
    "    t.assertEqual(x1_number_of_columns, 0)\n",
    "    t.assertEqual(x2_number_of_rows, 5)\n",
    "    t.assertEqual(x2_number_of_columns, 4)\n",
    "\n",
    "test_array_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "Return subarrays of the given arrays according to the conditions. Use array indexing e.g. `x1[1:5:-2]` instead of  loops or hardcoding the solutions.\n",
    "\n",
    "* Save the second to last element of `x1` in the variable `x1_second_to_last`.\n",
    "* Save a subarray that has every other element of `x1` in the variable `x1_every_other_element`.\n",
    "* Save a reversed `x1` in the variable `x1_reversed`.\n",
    "* Save the element in row 3 and column 2 of `x2` in the variable `x2_element_in_row_3_and_column_2`. Please note that since indexing starts at zero so row 3 is actually the forth row.\n",
    "* Save a subarray/matrix that contains rows 2 to 4 and columns 0 to 3 of `x2` in the variable `x2_rows_2_to_4_columns_0_to_3`. In this case row 4 and column 3 should be INCLUDED.\n",
    "\n",
    "Try **not** to use the shape or length of an array for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x1_second_to_last = x1[-2]\n",
    "x1_every_other_element = x1[::2]\n",
    "x1_reversed=x1[::-1]\n",
    "x2_element_in_row_3_and_column_2=x2[2,1]\n",
    "x2_rows_2_to_4_columns_0_to_3=x2[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test indexing solutions\n",
    "t.assertEqual(x1_second_to_last, 8)\n",
    "np.testing.assert_allclose(x1_every_other_element, np.array((4,4,8)))\n",
    "np.testing.assert_allclose(x1_reversed, np.array((4,8,4,4,3,4)))\n",
    "t.assertEqual(x2_element_in_row_3_and_column_2, 0)\n",
    "np.testing.assert_allclose(\n",
    "    x2_rows_2_to_4_columns_0_to_3, np.array(((3 ,0, 5, 0),(1, 2, 4 ,2),(0, 3 ,2 ,0)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Understanding broadcasting is an important part of understanding numpy.\n",
    "\n",
    "* Using `None` (`numpy.newaxis is None`), turn `array_a` into a column-vector and save the result in the variable `array_a_to_column_vector`.\n",
    "* Add the one-dimensional `array_a` and the two dimensional `array_b` together. Do not use any function and only the `+` operator.\n",
    "* Add the one-dimensional `array_a` and the two dimensional `array_c` together. Now it is important to use broadcasting since the dimensions of the two arrays do not match: `array_a.shape = (3,)` and `array_c.shape = (3,2).` Addition would work if the shape of `array_a` would be `(3,1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_a = np.ones(3)\n",
    "array_b = np.arange(6).reshape((2, 3))\n",
    "array_c = np.arange(6).reshape((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "array_a_to_column_vector = array_a[:, None]\n",
    "array_a + array_b\n",
    "array_a[:, None] + array_c\n",
    "print(array_a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test broadcasting solutions\n",
    "np.testing.assert_allclose(array_a_to_column_vector, np.ones(3).reshape(3, 1))\n",
    "np.testing.assert_allclose(array_a_plus_array_b, np.array(((1, 2, 3), (4, 5, 6))))\n",
    "np.testing.assert_allclose(array_a_plus_array_c, np.array(((1, 2), (3, 4), (5, 6))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting rules\n",
    "\n",
    "As mentioned in the lecture, broadcasting is a very powerful tool in numpy. It is therefore very helpful to understand the rules numpy follows when applying broadcasting.\n",
    "\n",
    "Refer to the numpy broadcasting documentation if you are unsure as to how broadcasting is applied: https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "\n",
    "The next cell will help us gain a better understanding of broadcasting and its rules. Fill in the variables with names `result_X` with the result of what the broadcasting operation of the two above shapes would be. If an error occurs, fill in `\"error\"` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_1_1 = (2, 3)\n",
    "shape_1_2 = (2, 1)\n",
    "\n",
    "shape_2_1 = (100, 3)\n",
    "shape_2_2 = (300, 3)\n",
    "\n",
    "\n",
    "shape_3_1 = (100, 3)\n",
    "shape_3_2 = (300, 1, 3)\n",
    "\n",
    "shape_4_1 =   (1,2,2,4,5)\n",
    "shape_4_2 = (1,1,2,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Please enter your solution here ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.assertEqual(result_1, np.broadcast_shapes(shape_1_1, shape_1_2))\n",
    "t.assertEqual(result_2, \"error\")\n",
    "t.assertEqual(result_3, np.broadcast_shapes(shape_3_1, shape_3_2))\n",
    "t.assertEqual(result_4, np.broadcast_shapes(shape_4_1, shape_4_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 2: NumPy Basics\n",
    "\n",
    "## Python Nearest Neighbor\n",
    "\n",
    "The most basic element of computation of nearest neighbors is its distance function relating two arbitrary data points `x1` and `x2`. We assume that these points are iterable (i.e. we can use a loop over their dimensions). One way among others to compute the **square** Euclidean distance between two points is by computing the sum of the component-wise distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pydistance(x1: np.ndarray, x2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the square Euclidean distance between two data points x1, x2\n",
    "\n",
    "    Args:\n",
    "        x1, x2: Two vectors (ndim=1) for which we want to calculate the distance\n",
    "            `len(x1) == len(x2)` will always be True\n",
    "\n",
    "    Returns:\n",
    "        float: The square Euclidean distance between the two vectors\n",
    "    \"\"\"\n",
    "    assert len(x1) == len(x2)\n",
    "    return sum((x1d - x2d) ** 2 for x1d, x2d in zip(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = [1, 4, 3, 2], [4, 8, -2, 2]\n",
    "print(f\"pydistance({x1}, {x1}) --> {pydistance(x1, x1)}\")\n",
    "print(f\"pydistance({x1}, {x2}) --> {pydistance(x1, x2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we use the prefix \"`py-`\" of the function to indicate that the latter makes use of pure `Python` instead of `numpy`. Once the distance matrix has been implemented, the nearest neighbor for a given unlabeled point `u` that we would like to classify is obtained by iterating over all points in the training set `(X, Y)`, selecting the point the with smallest distance to `u`, and returning its corresponding label. Here `X` denotes the list of inputs in the training set and `Y` denotes the list of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pynearest(u: np.ndarray, X: list, Y: list,\n",
    "              distance: Optional[Callable] = pydistance) -> int:\n",
    "    \"\"\"\n",
    "    Applies the nearest neighbor to the input `u`\n",
    "    with training set `X` and labels `Y`. The\n",
    "    distance metric can be specified using the\n",
    "    `distance` argument.\n",
    "\n",
    "    Args:\n",
    "        u: The input vector for which we want a prediction\n",
    "        X: A 2 dimensional list containing the trainig set\n",
    "        Y: A list containing the labels for each vector in the training set\n",
    "        distance: The distance metric. By default the `pydistance` function\n",
    "\n",
    "    Returns:\n",
    "        int: The label of the closest data point to u in X\n",
    "    \"\"\"\n",
    "    _, closest_point_label = min(zip(X, Y), key=lambda xy: distance(u, xy[0]))\n",
    "    return closest_point_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this function either uses function `pydistance` (given as default if the argument distance is not specified). Or one could specify as an argument a more optimized function for distance compuation, for example, one that uses `numpy`. Finally, one might not be interested in classifying a single point, but many of them. The method below receives a collection of such unlabeled test points stored in the variable `U`. The function returns a list of predictions associated with each test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pybatch(U: list, X: list, Y: list,\n",
    "            nearest: Optional[Callable] = pynearest,\n",
    "            distance: Optional[Callable] = pydistance) -> list[str]:\n",
    "    \"\"\"\n",
    "    Applies the nearest neighbor algorithm, to all the datapoints\n",
    "    `u` $\\in$ `U`, with `X` the training set and `Y` the labels.\n",
    "    Both the distance metric and the method of finding the\n",
    "    nearest neighbor can be specified.\n",
    "\n",
    "    Args:\n",
    "        U: List of vectors for which a prediction is desired.\n",
    "        X: A 2 dimensional list containing the training set\n",
    "        Y: A list containing the labels for each vector in the training set\n",
    "        nearest: The method by which the nearest neighbor search happens.\n",
    "        distance: The distance metric. By default the `pydistance` function\n",
    "\n",
    "    Returns:\n",
    "        list: A list of predicted labels for each `u` $\\in$ `U`\n",
    "    \"\"\"\n",
    "    return [nearest(u, X, Y, distance=distance) for u in U]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, such a function uses by default the Python nearest neighbor search (with a specified distance function). However, we can also specify a more optimized nearest neighbor function, for example, based on `numpy`. Finally, one could consider an alternative function to `pybatch` that would use `numpy` from the beginning to the end. The implementation of such more optimized functions, and the testing of their correct behavior and higher performance will be the objective of this exercise sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and correctness\n",
    "\n",
    "As a starting point, the code below tests the output of the nearest neighbor algorithm for some toy dataset with fixed parameters. In particular, the function `data.toy(M,N,d)` generates a problem with `M` unlabeled test points stored in a matrix `U` of size `(M x d)`, then `N` labeled training points stored in a matrix `X` of size `(N x d)` and the output label is stored in a vector `Y` of size `N` composed of zeros and ones encoding the two possible classes. The variable `d` denotes the number of dimensions of each point. The toy dataset is pseudo-random, that is, for fixed parameters, it produces a random-looking dataset, but every time the method is called with the same parameters, the dataset is the same. The pseudo-randomness property will be useful to verify that each nearest neighbor implementation performs the same overall computation. Please check the `data.py` file within the exercise folder for the implementation details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import data\n",
    "except ImportError:\n",
    "    print(\"\\n\\nDid you download the 'data.py' file from ISIS?\\n\\n\")\n",
    "    raise\n",
    "\n",
    "U, X, Y = data.toy(20, 100, 50)\n",
    "\n",
    "print(f\"Shape of U (unlabeled datapoints): {U.shape}\")\n",
    "print(f\"Shape of X (training set): {X.shape}\")\n",
    "print(f\"Shape of Y (labels): {Y.shape}\")\n",
    "print(f\"Predictions: {pybatch(U, X, Y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the output of this function will help us to verify that the more optimized `numpy`-based versions of nearest neighbor are still valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and performance\n",
    "\n",
    "We now describe how to build a plot that relates a certain parameter of the dataset (e.g. the number of input dimensions `d` to the time required for the computation. We first initialize the basic plotting environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the computation time of predicting `100` points from the test set using a training set of size `100`, where we vary the number of input dimensions. The measurement of time happens with the `timeit` module. `timeit` provides many convenient functions for benchmarking. In particular the repeat function runs the provided code many times and returns the time it took to run it. You can find more information about `repeat` [here](https://docs.python.org/3/library/timeit.html#timeit.repeat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from statistics import mean\n",
    "\n",
    "# Values for the number of dimensions d to test\n",
    "dlist = [1, 2, 5, 10, 20, 50, 100, 200, 500]\n",
    "\n",
    "# Measure the computation time for each choice of number of dimensions d\n",
    "tlist = []\n",
    "for d in dlist:\n",
    "    U, X, Y = data.toy(100, 100, d)\n",
    "    # get the average of three runs\n",
    "    delta = mean(timeit.repeat(lambda: pybatch(U, X, Y), number=1, repeat=3))\n",
    "    tlist.append(delta)\n",
    "\n",
    "# Create new figure\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "# Plot values\n",
    "plt.plot(dlist, tlist, \"-o\")\n",
    "# Add labels\n",
    "plt.xlabel(\"d\")\n",
    "plt.ylabel(\"time\")\n",
    "# Add grid\n",
    "plt.grid(True)\n",
    "# Set log scale\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time on the vertical axis is in seconds. Note that the exact computation time depends on the speed of your computer. As expected, the computation time increases with the number of input dimensions. Unfortunately, for the small dataset considered here (`100` training and test points of `100` dimensions each), the algorithm already takes more than one second to execute. Thus, it is necessary for practical applications (e.g. the digit recognition task that we will consider at the end of this exercise sheet) to accelerate this nearest neighbor algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Accelerating the distance computation\n",
    "\n",
    "In this first exercise, we would like to accelerate the function that computes pairwise distances.\n",
    "\n",
    "### 1.1 npdistance\n",
    "Implement the function `npdistance(x1,x2)` with the same output as `pydistance(x1,x2)`, but that computes the squared Euclidean distance using `numpy` operations.\n",
    "\n",
    "Our goal with this exercise is to speed up our code. In practice this means that we want to remove for loops from our code. Therefore your implementation should not contain a `for loop`. Similarly, Python functions that hide for loops such as `map` are also considered invalid for this exercise. Similarly, functions provided by numpy that \"hide\" for loops like [`vectorize`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.vectorize.html) and [`apply_along_axis`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.apply_along_axis.html) are also **not** to be used. Further the built-in function `sum` is not allowed to be used, however `np.sum` can be used.\n",
    "\n",
    "**Note**: The input vectors can be either `np.ndarray` or lists of `floats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@no_loops_allowed\n",
    "@no_imports\n",
    "def npdistance(x1: np.ndarray, x2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the square Euclidean distance between two data points x1, x2\n",
    "    using `numpy` vectorized operations\n",
    "\n",
    "    Args:\n",
    "        x1, x2: Two vectors (ndim=1) for which we want to calculate the distance\n",
    "                `len(x1) == len(x2)` will always be True\n",
    "\n",
    "    Returns:\n",
    "        float: The distance between the two vectors x1, x2\n",
    "    \"\"\"\n",
    "\n",
    "### Please enter your solution here ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify your function\n",
    "def test_npdistance():\n",
    "    x1, x2 = [0.0, -1.0, -2.0], [2.0, 3.0, 4.0]\n",
    "\n",
    "    # test vector distance to itself\n",
    "    dist_to_same = npdistance(x1, x1)\n",
    "    print(f\"npdistance({x1}, {x1}) --> {dist_to_same}\\n\")\n",
    "    expected_dist_to_same = 0.0\n",
    "    t.assertAlmostEqual(\n",
    "        dist_to_same,\n",
    "        expected_dist_to_same,\n",
    "        msg=\"The distance of a vector to itself should be 0\",\n",
    "    )\n",
    "\n",
    "    # test against pydistance\n",
    "    dist = npdistance(x1, x2)\n",
    "    print(f\"npdistance({x1}, {x2}) --> {dist}\")\n",
    "    expected_dist = pydistance(x1, x2)\n",
    "    print(f\"expected_dist --> {expected_dist}\\n\")\n",
    "    t.assertAlmostEqual(dist, expected_dist)\n",
    "\n",
    "    U, X, Y = data.toy(20, 100, 50)\n",
    "    no_numpy = pybatch(U, X, Y, distance=pydistance)\n",
    "    print(f\"no_numpy --> {no_numpy}\")\n",
    "    w_np_dist = pybatch(U, X, Y, distance=npdistance)\n",
    "    print(f\"w_np_dist  --> {w_np_dist}\")\n",
    "    np.testing.assert_allclose(no_numpy, w_np_dist)\n",
    "\n",
    "    npdistance.assert_no_imports()\n",
    "    npdistance.assert_not_too_many_loops()\n",
    "\n",
    "test_npdistance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Plotting\n",
    "Create a plot similar to the one above, but that shows the computation time required by both methods shown in the same plot. There should be two lines, one for for `pydistance` and another for `npdistance`, displayed in the same plane. Here, we fix `M=100`, `N=100`, and we let `d` vary from `1` to `500`, taking the list of values `[1, 2, 5, 10, 20, 50, 100, 200, 500]`. Your plot should show a quasi-constant runtime for the `pybatch` call using the `npdistance` function, compared to `pydistance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Please enter your solution here ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Accelerating the nearest neighbor search\n",
    "\n",
    "Motivated by the success of the `numpy` optimized distance computation, we would like to further accelerate the code by performing nearest neighbor search directly in `numpy`.\n",
    "\n",
    "### 2.1 npnearest\n",
    "Implement the function `npnearest(u,X,Y)` as an alternative to the function `pynearest(u,X,Y,distance=npdistance)` that we have used in the previous exercise. Again, verify your function for the same toy example as before (i.e. `data.toy(20,100,50)`).\n",
    "\n",
    "Unlike `pynearest`, `npnearest` doesn't receive any distance argument. `npnearest` will work only with square Euclidean distance. If you are confident that your `npdistance` implementation can work between a vector and a matrix, you are welcome to reuse it. It is, however, perfectly acceptable to reimplement the distance algorithm in this function again.\n",
    "\n",
    "Once again the use of `for loops`, or functions like `map` or `np.vectorize` is strictly not allowed in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@no_loops_allowed\n",
    "@no_imports\n",
    "def npnearest(u: np.ndarray, X: np.ndarray, Y: np.ndarray, *args, **kwargs) -> int:\n",
    "    \"\"\"\n",
    "    Finds xi so that xiis in X and u and xi have a minimal distance compared\n",
    "    to all other data points in X. Returns the label of xi.\n",
    "\n",
    "    Args:\n",
    "        u: The vector (ndim=1) we want to classify\n",
    "        X: A matrix (ndim=2) with training data points (vectors)\n",
    "        Y: A vector containing the label of each data point in X\n",
    "        args, kwargs: Ignored. Only for compatibility with pybatch\n",
    "\n",
    "    Returns:\n",
    "        int: The label of the data point which is closest to `u`\n",
    "    \"\"\"\n",
    "\n",
    "### Please enter your solution here ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify your function\n",
    "\n",
    "def test_npnearest():\n",
    "    TINY_U, TINY_X, TINY_Y = data.toy(3, 3, 3)\n",
    "    tiny_u = TINY_U[0]\n",
    "    print(\"u\")\n",
    "    pprint(tiny_u)\n",
    "    print(\"\\nX\")\n",
    "    pprint(TINY_X)\n",
    "    print(\"\\nY\")\n",
    "    pprint(TINY_Y)\n",
    "\n",
    "    np_nearest = npnearest(tiny_u, TINY_X, TINY_Y)\n",
    "    expected_nearest = pynearest(tiny_u, TINY_X, TINY_Y)\n",
    "    print(f\"\\nnp_nearest --> {np_nearest}\")\n",
    "    print(f\"expected_nearest --> {expected_nearest}\")\n",
    "\n",
    "    t.assertEqual(expected_nearest, np_nearest)\n",
    "\n",
    "    np.testing.assert_allclose(\n",
    "        pybatch(U, X, Y, nearest=pynearest), pybatch(U, X, Y, nearest=npnearest)\n",
    "    )\n",
    "\n",
    "    npnearest.assert_no_imports()\n",
    "    npnearest.assert_not_too_many_loops()\n",
    "\n",
    "test_npnearest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Plotting \n",
    "Create a plot similar to the one above, where the new method is compared to the previous one. This means that you should compare the runtime of `npnearest` and `pynearest` with `npdistance` as its distance function. Here, we fix `M=100`, `d=100`, and we let `N` take different values `[1, 2, 5, 10, 20, 50, 100, 200, 500]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Please enter your solution here ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accelerating the processing of multiple test points\n",
    "\n",
    "Not yet fully happy with the performance of the algorithm, we would like to further optimize it by avoiding performing a loop on the test points, and instead, classify them all at once.\n",
    "\n",
    "### 3.1 npbatch\n",
    "Implement the function `npbatch(U,X,Y)` as a replacement of the implementation `pybatch(U,X,Y,nearest=npnearest)` that we have built in the previous exercise. Inside this function, use [`scipy.spatial.distance.cdist`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html) for the actual distance computation. When using `scipy.spatial.distance.cdist`, recall that our previous distance functions compute the squared euclidean distance, and to select the appropriate parameters to match this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "\n",
    "@no_loops_allowed\n",
    "@no_imports\n",
    "def npbatch(U: np.ndarray, X: np.ndarray, Y: np.ndarray, *args, **kwargs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function has the same functionality as the `pybatch` function.\n",
    "    HOWEVER, the distance function is fixed (scipy.spatial.distance.cdist).\n",
    "    It does not use any of the functions defined by us previously.\n",
    "\n",
    "    Args:\n",
    "        U: A matrix (ndim=2) containing multiple vectors which we want to classify\n",
    "        X: A matrix (ndim=2) that represents the training data\n",
    "        Y: A vector (ndim=1) containing the labels for each data point in X\n",
    "        args, kwargs: Ignored. Only for compatibility with pybatch\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A vector (ndim=1) with the predicted label for each vector $u \\in U$\n",
    "    \"\"\"\n",
    "\n",
    "### Please enter your solution here ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_npbatch():\n",
    "    TINY_U, TINY_X, TINY_Y = data.toy(3, 3, 3)\n",
    "    \n",
    "    print(\"U\")\n",
    "    pprint(TINY_U)\n",
    "    print(\"\\nX\")\n",
    "    pprint(TINY_X)\n",
    "    print(\"\\nY\")\n",
    "    pprint(TINY_Y)\n",
    "\n",
    "    expected_output = pybatch(TINY_U, TINY_X, TINY_Y)\n",
    "    print(f\"\\nexpected_output --> {expected_output}\")\n",
    "    actual_output = npbatch(TINY_U, TINY_X, TINY_Y)\n",
    "    print(f\"actual_output --> {actual_output}\")\n",
    "    np.testing.assert_allclose(expected_output, actual_output)\n",
    "\n",
    "    U, X, Y = data.toy(20, 100, 50)\n",
    "    np.testing.assert_allclose(pybatch(U, X, Y), npbatch(U, X, Y))\n",
    "\n",
    "    npbatch.assert_no_imports()\n",
    "    npbatch.assert_not_too_many_loops()\n",
    "\n",
    "test_npbatch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plotting\n",
    "Create a plot comparing the computation time of the new implementation compared to the previous one. Here, we fix `N=100`, `d=100`, and we let `M` vary from `1` to `500` with values `[1, 2, 5, 10, 20, 50, 100, 200, 500]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Please enter your solution here ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Application to real-world data\n",
    "\n",
    "Having now implemented an efficient K-nearest neighbor classifier, we can test it on real problems with many data points and dimensions. We consider a small handwritten digits recognition dataset, that can be directly obtained from the library `scikit-learn`. This dataset consists of handwritten digits of size `8 x 8` flattened into arrays of size `64`, with class between `0` and `9`. We use the function `data.digits()` to load the data and arrange data points in some predefined order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data.digits()\n",
    "print(f\"Shape of data: {X.shape}\")\n",
    "print(f\"Shape of labels: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the first data point\n",
    "\n",
    "In the following cell we will visualize the first data point in the dataset. This will serve as a demonstration as to how we can plot image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = X[0].reshape(8,8)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(first_image, cmap=\"Greys\")\n",
    "plt.title(f'The label of the first datapoint is {Y[0]}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Plotting\n",
    "Using the function `imshow` of `matplotlib.pyplot (plt)` to visualize the first 16 digits (in a `4x4` grid) of the dataset. For the sake of the exercise, try to write it without using any loops or individually setting the placement of each image, which is essentially just unrolling the loop.\n",
    "\n",
    "**Hint**: Use the `np.transpose` and `np.reshape` functions, to implement the function without any loops.\n",
    "\n",
    "**Note**: Your solution should output exactly one plot and shouldn't create new figures i.e. call `plt.show` or use `plt.figure` in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@max_allowed_loops(1)  # but try to use 0\n",
    "@no_imports\n",
    "def plot_first_digits():\n",
    "    \"\"\"\n",
    "    Loads the digit dataset and plots the first 16 digits in one image\n",
    "    You are encouraged to implement this function without\n",
    "    the use of any for-loops. A solution that does not use loops\n",
    "    calls plt.imshow once and does not use an unrolled loop.\n",
    "    \"\"\"\n",
    "\n",
    "### Please enter your solution here ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_first_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train-test-split\n",
    "Now that we are somewhat familiar with the dataset we are working with, we want to use the k-nearest-neighbor classifier that we implemented above. For this we want to apply the following steps.\n",
    "\n",
    "* Partition the data into a \"training\" set and \"test\" set. The training set contains the first 1000 digits of `X`, and the test set contains the remaining ones. You will implement the `train_test_split` function for this task.\n",
    "\n",
    "* Implement the `predict` function which is a wrapper around the npbatch function. It receives the training data and labels as well as test data for which we want to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x: np.ndarray, y: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets\n",
    "    The first 1000 samples belong to the training set the rest to the test set\n",
    "\n",
    "    Args:\n",
    "        x: A matrix (ndim=2) containing the data\n",
    "        y: A vector (ndim=1) containing the label for each datapoint\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing 4 elements. The training data, the test data, the training labels\n",
    "               and the test labels\n",
    "    \"\"\"\n",
    "\n",
    "### Please enter your solution here ###\n",
    "\n",
    "\n",
    "\n",
    "def predict(x_train: np.ndarray, x_test: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For each x in x_test this function finds the nearest neighbour in x_train and\n",
    "    returns that label\n",
    "\n",
    "    This function is a wrapper of the `npbatch` function\n",
    "\n",
    "    Args:\n",
    "        x_train: A matrix (ndim=2) containing all the training data\n",
    "        x_test: A matrix (ndim=2) containing all the test data for which we want a prediction\n",
    "        y_train: A vector (ndim=1) containing the label of each data point in the training set\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A vector with the prediction for each datapoint/vector in x_test\n",
    "    \"\"\"\n",
    "\n",
    "### Please enter your solution here ###\n",
    "\n",
    "    return y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the train_test_split function\n",
    "def test_train_test_split():\n",
    "    train_test_output = train_test_split(X, Y)\n",
    "    x_train, x_test, y_train, y_test = train_test_output\n",
    "\n",
    "    # check if types match\n",
    "    t.assertIsInstance(x_train, np.ndarray)\n",
    "    t.assertIsInstance(x_test, np.ndarray)\n",
    "    t.assertIsInstance(y_train, np.ndarray)\n",
    "    t.assertIsInstance(y_test, np.ndarray)\n",
    "\n",
    "    # check if shapes match\n",
    "    t.assertEqual(x_train.shape, (1000, 64))\n",
    "    t.assertEqual(x_test.shape, (797, 64))\n",
    "    t.assertEqual(y_train.shape, (1000,))\n",
    "    t.assertEqual(y_test.shape, (797,))\n",
    "\n",
    "    # check that the first values match\n",
    "    t.assertEqual(y_train[0], 7)\n",
    "    t.assertEqual(y_test[0], 0)\n",
    "\n",
    "test_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the predict function\n",
    "def test_predict():\n",
    "    train_test_output = train_test_split(X, Y)\n",
    "    x_train, x_test, y_train, y_test = train_test_output\n",
    "    \n",
    "    # check if prediction shape matches\n",
    "    predictions = predict(x_train, x_test, y_train)\n",
    "    t.assertEqual(predictions.shape, (797,))\n",
    "\n",
    "    first_three = predictions[:3]\n",
    "    print(f\"first_three --> {first_three.tolist()}\")\n",
    "\n",
    "    expected_first_three = pybatch(x_test[:3], x_train, y_train)\n",
    "    print(f\"expected_first_three --> {expected_first_three}\")\n",
    "\n",
    "    np.testing.assert_allclose(first_three, expected_first_three)\n",
    "\n",
    "test_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Evaluation\n",
    "As a final step we want to gauge the accuracy of our classifier. We will therefore compare the predictions of our classifier on the test data with the ground truth (the labels of the test data).\n",
    "\n",
    "* Implement the `evaluate` function which returns the fraction (ratio) of the test set where the predictions of the nearest neighbor algorithm and labels disagree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x_train: np.ndarray, x_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates the accuracy of our nearest neighbor classifier\n",
    "    by calculating the proportion of test samples for which\n",
    "    our classification method disagrees with the ground truth.\n",
    "\n",
    "    Args:\n",
    "        x_train: A matrix (ndim=2) containing the training data for the classifier\n",
    "        x_test: A matrix (ndim=2) containing the test data for which the classifier\n",
    "        will make a prediction\n",
    "        y_train: The labels for the training data\n",
    "        y_test: The labels for the test data\n",
    "        \n",
    "    Returns:\n",
    "        float: The proportion in [0-1] of the test samples for which our\n",
    "               nearest neighbor classifier disagrees with the provided labels\n",
    "    \"\"\"\n",
    "\n",
    "### Please enter your solution here ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y)\n",
    "    ratio_disagree = evaluate(x_train, x_test, y_train, y_test)\n",
    "    print(f\"ratio_disagree --> {ratio_disagree}\")\n",
    "\n",
    "    # make sure this is a percentage\n",
    "    t.assertGreaterEqual(ratio_disagree, 0.0, \"A percentage cannot be less than 0\")\n",
    "    t.assertLessEqual(ratio_disagree, 1.0, \"A percentage cannot be more than 1\")\n",
    "\n",
    "    # Upper bound for disagree ratio\n",
    "    t.assertLess(ratio_disagree, 0.009, \"Your solution should return less than 0.009\")\n",
    "    t.assertGreater(ratio_disagree, 0.008, \"Your solution should return more than 0.008\")\n",
    "\n",
    "test_evaluate()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python (.venv deep_learning)",
   "language": "python",
   "name": "deep_learning_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
