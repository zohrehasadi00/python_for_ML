{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "To each task tests are provided. You can use these tests to practice test driven development (TDD), but please note that using them will likely make the tasks easier.\n",
    "Please also not that the tests may not be exhaustive, i.e. even when passing all tests, your solution can still be imperfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is for setting up the testing. Please execute it.\n",
    "\n",
    "# Use unittest asserts\n",
    "import unittest\n",
    "\n",
    "t = unittest.TestCase()\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Helper assert function\n",
    "def assert_percentage(val):\n",
    "    t.assertGreaterEqual(val, 0.0, f\"Percentage ({val}) cannot be < 0\")\n",
    "    t.assertLessEqual(val, 1.0, f\"Percentage ({val}) cannot be > 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm Ups\n",
    "\n",
    "Before starting the homework sheet we recommend you finish these warm-up tasks. They should help you to get familiar with Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function and types\n",
    "\n",
    "Write a function using a list comprehension that returns the types of the elements in the list.\n",
    "\n",
    "* The function should be called `types_of`\n",
    "* The function expects a list as an input argument.\n",
    "* The function should return a list with the types of the given list elements.\n",
    "* Read the testing cell to understand how `types_of` is supposed to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[int, float, bool, int]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Please enter your solution here ###\n",
    "def types_of(l: list) -> list:\n",
    "    return [type(elem) for elem in l]\n",
    "\n",
    "\n",
    "types_of([2, 2.0, True, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test type_of function\n",
    "import ast\n",
    "import inspect\n",
    "\n",
    "def test_types_of():\n",
    "    types = types_of([7, 0.7, \"hello\", True, (2, \"s\")])\n",
    "    assert isinstance(types, list)\n",
    "    t.assertEqual(types[0], int)\n",
    "    t.assertEqual(types[1], float)\n",
    "    t.assertEqual(types[2], str)\n",
    "    t.assertEqual(types[3], bool)\n",
    "    t.assertEqual(types[-1], tuple)\n",
    "    t.assertEqual([int, float, str, bool, tuple], types)\n",
    "\n",
    "    # check that the function uses a list comprehension\n",
    "    source = inspect.getsource(types_of)\n",
    "    for node in ast.walk(ast.parse(source)):\n",
    "        if isinstance(node, ast.ListComp):\n",
    "            break\n",
    "    else:\n",
    "        t.fail(\"types_of does not use a list comprehension\")\n",
    "\n",
    "test_types_of()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Math Operations and Interpreting Formulas\n",
    "\n",
    "Some machine learning methods require data normalization as a pre-processing step. Write a function normalize_list that takes a list of numbers and performs normalization in two different ways:\n",
    "1. min-max feature scaling: scales the $x_i$ to a given range [a, b]. When [a,b] = [0,1], sometimes called min-max normalization.\n",
    "$$ x_i' = a + \\frac{(b-a)(x_i - \\min{x})}{\\max{x} - \\min{x}} $$\n",
    "2. Scaling to unit length. \n",
    "$$ x_i' = \\frac{x}{\\|x\\|_2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.0, 0.25, 0.5, 0.75, 1.0], [0.13483997249264842, 0.26967994498529685, 0.40451991747794525, 0.5393598899705937, 0.674199862463242])\n",
      "([1.0, 1.25, 1.5, 1.75, 2.0], [0.13483997249264842, 0.26967994498529685, 0.40451991747794525, 0.5393598899705937, 0.674199862463242])\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "from torch import norm\n",
    "\n",
    "def normalize_list(values: list[float], range_: tuple[float, float] = (0.0, 1.0)) -> tuple[list[float], list[float]]:\n",
    "    a, b = range_\n",
    "    min_x = min(values)\n",
    "    max_x = max(values)\n",
    "    normalized_values = [a + ((b -a)*(x - min_x)/(max_x - min_x)) for x in values]\n",
    "    norm_x = sqrt(sum(i**2 for i in values))\n",
    "    unit_scaled_values = [x / norm_x for x in values]\n",
    "\n",
    "    return (normalized_values, unit_scaled_values)\n",
    "\n",
    "# Test\n",
    "values = [1, 2, 3, 4, 5]\n",
    "print(normalize_list(values))  \n",
    "print(normalize_list(values, (1.0, 2.0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String formatting\n",
    "\n",
    "What does the following string formatting evaluate to?\n",
    "* Write the result of the string formatting into the variables result1, result2, result3.\n",
    "* Example: `string0 = \"This is a {} string.\".format(\"test\")`\n",
    "* Example solution: `result0 = \"This is a test string\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first string\n",
    "string1 = \"The sky is {}. {} words in front of {} random words create {} random sentence.\".format(\n",
    "    \"clear\", \"Random\", \"other\", 1\n",
    ")\n",
    "\n",
    "# second string\n",
    "a = \"irony\"\n",
    "b = \"anyone\"\n",
    "c = \"room\"\n",
    "\n",
    "string2 = f\"The {a} of the situation wasn't lost on {b} in the {c}.\"\n",
    "\n",
    "# third string\n",
    "string3 = f\"{7*10} * {9/3} with three digits after the floating point looks like this: {70*3 :.3f}.\"\n",
    "\n",
    "# fourth string\n",
    "string4 = \"   Hello World.   \".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Please enter your solution here ###\n",
    "result1=\"The sky is clear. Random words in front of other random words create 1 random sentence.\"\n",
    "result2 = \"The irony of the situation wasn't lost on anyone in the room.\"\n",
    "result3 = \"70 * 3.0 with three digits after the floating point looks like this: 210.000.\"\n",
    "result4 = \"Hello World.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the string results\n",
    "t.assertEqual(string1, result1)\n",
    "t.assertEqual(string2, result2)\n",
    "t.assertEqual(string3, result3)\n",
    "t.assertEqual(string4, result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation and Enumeration\n",
    "\n",
    "\n",
    "Concatenate the strings from the array 'animals' into one string using a for-loop.\n",
    "\n",
    "* Use: `counting +=` and string formatting (`f-strings`).\n",
    "* Use `enumerate` to get the `i`th index.\n",
    "* The result should look as follows: `'| 0: mouse | 1: rabbit | 2: cat | 3: dog |'`\n",
    "\n",
    "***Note that this is not the most efficient way to concatenate strings in Python but part of this exercise is to showcase `for-loops`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = [\"mouse\", \"rabbit\", \"cat\", \"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 0: mouse | 1: rabbit | 2: cat | 3: dog |\n"
     ]
    }
   ],
   "source": [
    "counting = \"|\"\n",
    "\n",
    "for index, item in enumerate(animals):\n",
    "    counting += f\" {index}: {item} |\"\n",
    "\n",
    "print(counting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of the enumeration loop\n",
    "t.assertEqual(counting, \"| 0: mouse | 1: rabbit | 2: cat | 3: dog |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Oriented Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person Class\n",
    "\n",
    "Create a class called `Person` with the following attributes:\n",
    "- `name` (string)\n",
    "- `age` (integer)\n",
    "- `hobbies` (list of strings)\n",
    "\n",
    "The initialization method (`__init__`) should receive the attributes as arguments and assign them to the object.\n",
    "\n",
    "Define a method called `introduction` that prints and returns the following for a person called `John` with age `30` and hobbies `[\"reading\", \"hiking\", \"swimming\"]`:\n",
    "\n",
    "`\"Hello, my name is John and I am 30 years old. My hobbies are: reading, hiking, swimming.\"`\n",
    "\n",
    "If the person has no hobbies (i.e. the list of hobbies is empty), the method should print and return:\n",
    "\n",
    "`\"Hello, my name is John and I am 30 years old. I have no hobbies.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person():\n",
    "    def __init__(self, name:str , age:int , hobbies:list) -> str:\n",
    "        self.name = name\n",
    "        self.age = age \n",
    "        self.hobbies = hobbies\n",
    "\n",
    "    def introduction(self):\n",
    "        name_and_age= f\"Hello, my name is {self.name} and I am {self.age} years old.\"\n",
    "        if not self.hobbies:\n",
    "            statement = f\"{name_and_age} I have no hobbies.\"\n",
    "            print(statement)\n",
    "            return statement\n",
    "        h = \", \".join(self.hobbies)\n",
    "        statement = f\"{name_and_age} My hobbies are: {h}.\"\n",
    "        print(statement)\n",
    "        return statement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Alice and I am 25 years old. My hobbies are: reading, swimming.\n",
      "Hello, my name is Bob and I am 30 years old. I have no hobbies.\n",
      "Hello, my name is Charlie and I am 40 years old. My hobbies are: reading.\n"
     ]
    }
   ],
   "source": [
    "# Test person class\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "def test_Person():\n",
    "    p1 = Person(\"Alice\", 25, [\"reading\", \"swimming\"])\n",
    "    p2 = Person(\"Bob\", 30, [])\n",
    "    p3 = Person(\"Charlie\", 40, [\"reading\"])\n",
    "\n",
    "    t.assertEqual(p1.introduction(), \"Hello, my name is Alice and I am 25 years old. My hobbies are: reading, swimming.\")\n",
    "    t.assertEqual(p2.introduction(), \"Hello, my name is Bob and I am 30 years old. I have no hobbies.\")\n",
    "    t.assertEqual(p3.introduction(), \"Hello, my name is Charlie and I am 40 years old. My hobbies are: reading.\")\n",
    "\n",
    "    # check that method prints the correct string\n",
    "    f = io.StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        p1.introduction()\n",
    "        output = f.getvalue().strip()\n",
    "\n",
    "    if output == '':\n",
    "        t.fail(\"The method does not seem to print anything.\")\n",
    "\n",
    "    t.assertEqual(output, \"Hello, my name is Alice and I am 25 years old. My hobbies are: reading, swimming.\", \n",
    "                          \"The method should print the correct string.\")\n",
    "\n",
    "test_Person()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 1: Python Basics\n",
    "\n",
    "This exercise sheet examines the basic functionalities of the Python programming language in the context of a simple prediction task. We consider the problem of predicting the health risks of subjects from their personal data and habits. We first try to accomplish this task by using a decision tree.\n",
    "\n",
    "![](tree.png)\n",
    "\n",
    "Make sure that you have downloaded the `tree.png` file from ISIS. For this exercise sheet, you are required to use only pure Python and, to not import any module, including `NumPy`. Next week we will implement the nearest neighbor part of this exercise sheet using `NumPy` ðŸ˜‰."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classifying a single instance\n",
    "\n",
    "* In this sheet we represent patient info as a tuple.\n",
    "* Implement the function `decision` that takes as input a tuple containing values for attributes `(smoker, age, diet)`, and computes the output of the decision tree. The function should return either `'less'` or `'more'`. No other outputs are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision(x: tuple[str, int, str]) -> str:\n",
    "    \"\"\"\n",
    "    Implements the decision tree represented in the image above. As input the function\n",
    "    receives a tuple with three values that represent some information about a patient.\n",
    "    \n",
    "    Args:\n",
    "        x: Input tuple containing exactly three values.\n",
    "           The first element is a string and represents if a patient is a smoker. \n",
    "           If they do smoke, this string will be 'yes'. All other values represent \n",
    "           that the patient is not a smoker.\n",
    "           The second element represents the age of a patient in years as an integer.\n",
    "           The last element represents the diet of a patient. If a patient has a good diet this\n",
    "           string will be 'good'. All other values represent that the patient has a poor diet.\n",
    "    \n",
    "    Returns:\n",
    "        str: A string that has either the value 'more' or 'less'. No other return value\n",
    "             is valid.\n",
    "    \"\"\"\n",
    "    smoker, age, diet = x\n",
    "    if smoker == \"yes\":\n",
    "        if age >= 29.5:\n",
    "            return \"more\"\n",
    "        else:\n",
    "            return \"less\"\n",
    "    else:\n",
    "        if diet==\"good\":\n",
    "            return \"less\"\n",
    "        else:\n",
    "            return \"more\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision(('yes', 31, 'good')) --> more\n",
      "decision(('yes', 29, 'poor')) --> less\n"
     ]
    }
   ],
   "source": [
    "# Test decision function\n",
    "def test_decision():\n",
    "    try:\n",
    "        t\n",
    "    except NameError:\n",
    "        print(\"No test object found. Did you run the first cell?\")\n",
    "        raise\n",
    "\n",
    "    # Test expected 'more'\n",
    "    x = (\"yes\", 31, \"good\")\n",
    "    output = decision(x)\n",
    "    print(f\"decision({x}) --> {output}\")\n",
    "    t.assertIsInstance(output, str)\n",
    "    t.assertEqual(output, \"more\")\n",
    "\n",
    "    # Test expected 'less'\n",
    "    x = (\"yes\", 29, \"poor\")\n",
    "    output = decision(x)\n",
    "    print(f\"decision({x}) --> {output}\")\n",
    "    t.assertIsInstance(output, str)\n",
    "    t.assertEqual(output, \"less\")\n",
    "\n",
    "test_decision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading a dataset from a text file\n",
    "In the previous task we created a method to classify the risk of patients, by manually setting rules defining for which inputs the user is in `more` or `less` risk regarding their health. In the next exercises we will approach the task differently. Our goal is to create a classification method based on data. In order to achieve this we need to also create functions that load the existing data into the program so that we can use it. Furthermore, we can use the loaded data as input for our decision tree implementation and check what it outputs.\n",
    "\n",
    "The file `health-test.txt` contains several fictitious records of personal data and habits. We split this task into two parts. In the first part, we assume that we have read a line from the file and can now process it. In the second function, we load the file and process each line using the function we have defined for this purpose.\n",
    "\n",
    "* Read the file automatically using the methods introduced during the lecture.\n",
    "* Represent the dataset as a list of tuples. Make sure that the tuples have the same format as in the previous task, e.g. `('yes', 31, 'good')`.\n",
    "\n",
    "**Notes**: \n",
    "* Make sure that you close the file after you have opened it and read its content. If you use a `with` statement then you don't have to worry about closing the file.\n",
    "* Make sure when opening a file not to use an absolute path. An absolute path will work on your computer, but when your code is tested on the department's computers, it will fail. Use relative paths when opening files.\n",
    "* Values read from files are always strings.\n",
    "* Each line contains a newline `\\n` character at the end.\n",
    "* If you are using Windows as your operating system, refrain from opening any text files using Notepad. It will remove any linebreaks `\\n`. You should inspect the files using the Jupyter text editor or any other modern text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line_test(line: str) -> tuple[str, int, str]:\n",
    "    \"\"\"\n",
    "    Takes a line from the file, including a newline, and parses it into a patient tuple.\n",
    "\n",
    "    Args:\n",
    "        line: A line from the `health-test.txt` file\n",
    "    Returns:\n",
    "        tuple: A tuple representing a patient\n",
    "    \"\"\"\n",
    "    assert (\n",
    "        line[-1] == \"\\n\"\n",
    "    ), \"Did you change the contents of the line before calling this function?\"\n",
    "    smoker, age, diet = line.strip(\"\\n\").split(\",\")\n",
    "    return smoker, int(age), diet\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', 23, 'good')\n"
     ]
    }
   ],
   "source": [
    "def test_parse_line_test():\n",
    "    x = \"yes,23,good\\n\"\n",
    "    parsed_line = parse_line_test(x)\n",
    "    smoker, age, diet = parsed_line\n",
    "    print(parsed_line)\n",
    "    t.assertIsInstance(parsed_line, tuple)\n",
    "    t.assertEqual(len(parsed_line), 3)\n",
    "    t.assertIsInstance(age, int)\n",
    "    t.assertNotIn(\"\\n\", diet, \"Are you handling line breaks correctly?\")\n",
    "    t.assertEqual(parsed_line[-1], \"good\")\n",
    "    \n",
    "test_parse_line_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettest() -> list[tuple[str, int, str]]:\n",
    "    \"\"\"\n",
    "    Opens the `health-test.txt` file and parses it\n",
    "    into a list of patient tuples. You are encouraged to use\n",
    "    the `parse_line_test` function but it is not necessary to do so.\n",
    "\n",
    "    This function assumes that the `health-test.txt` file is located in\n",
    "    the same directory as this notebook.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of patient tuples as read from the file\n",
    "    \"\"\"\n",
    "    patients = []  \n",
    "    with open(\"health-test.txt\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            patients.append(parse_line_test(line))\n",
    "        \n",
    "    return patients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yes', 21, 'poor'),\n",
      " ('no', 50, 'good'),\n",
      " ('no', 23, 'good'),\n",
      " ('yes', 45, 'poor'),\n",
      " ('yes', 51, 'good'),\n",
      " ('no', 60, 'good'),\n",
      " ('no', 15, 'poor'),\n",
      " ('no', 18, 'good')]\n"
     ]
    }
   ],
   "source": [
    "def test_gettest():\n",
    "    testset = gettest()\n",
    "    pprint(testset)\n",
    "    t.assertIsInstance(testset, list)\n",
    "    t.assertEqual(len(testset), 8)\n",
    "    t.assertIsInstance(testset[0], tuple)\n",
    "\n",
    "test_gettest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Applying the decision tree to the dataset\n",
    "\n",
    "* Apply the decision tree to all points in the dataset, and return the proportion of them that are classified as \"more\".\n",
    "* A proportion is a value in [0-1]. So if out of 50 data points 15 return `\"more\"` the value that should be returned is `0.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis is a shorter way:\\ndef evaluate_testset(dataset: list[tuple[str, int, str]]) -> float:\\n    total = len(dataset)\\n    mores = sum(decision(x) == \"more\" for x in dataset)\\n    return mores / total if total else 0.0  # guard optional\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from asyncio.proactor_events import _ProactorBasePipeTransport\n",
    "from socketserver import DatagramRequestHandler\n",
    "\n",
    "\n",
    "def evaluate_testset(dataset: list[tuple[str, int, str]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the percentage of data points for which the\n",
    "    decision function evaluates to `more` for a given dataset\n",
    "\n",
    "    Args:\n",
    "        dataset: A list of patient tuples\n",
    "\n",
    "    Returns:\n",
    "        float: The percentage of data points that are evaluated to `'more'`\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(dataset)\n",
    "    mores = 0\n",
    "    for x in dataset:\n",
    "        if decision(x)==\"more\":\n",
    "            mores+=1\n",
    "    return mores/total if total else 0.0\n",
    "\n",
    "\"\"\"\n",
    "this is a shorter way:\n",
    "def evaluate_testset(dataset: list[tuple[str, int, str]]) -> float:\n",
    "    total = len(dataset)\n",
    "    mores = sum(decision(x) == \"more\" for x in dataset)\n",
    "    return mores / total if total else 0.0  # guard optional\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio --> 0.375\n"
     ]
    }
   ],
   "source": [
    "def test_evaluate_testset():\n",
    "    ratio = evaluate_testset(gettest())\n",
    "    print(f\"ratio --> {ratio}\")\n",
    "    t.assertIsInstance(ratio, float)\n",
    "    assert_percentage(ratio)\n",
    "    t.assertTrue(0.3 < ratio < 0.4)\n",
    "\n",
    "test_evaluate_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Learning from examples\n",
    "Suppose that instead of relying on a fixed decision tree, we would like to use a data-driven approach where data points are classified based on a set of training observations manually labeled by experts. Such labeled dataset is available in the file `health-train.txt`. The first three columns have the same meaning as in `health-test.txt`, and the last column corresponds to the labels.\n",
    "\n",
    "* Read the `health-train.txt` file and convert it into a list of pairs. The first element of each pair is a triplet of attributes (the patient tuple), and the second element is the label.\n",
    "* Similarly to the previous exercise we split the task into two parts. The first involves processing each line individually. The second handles opening the file and processing all lines of the file\n",
    "\n",
    "**Note**: A triplet is a tuple that contains exactly three values, a pair is a tuple that contains exactly two values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line_train(line: str) -> tuple[tuple[str, int, str], str]:\n",
    "    \"\"\"\n",
    "    This function works similarly to the `parse_line_test` function.\n",
    "    It parses a line of the `health-train.txt` file into a tuple that\n",
    "    contains a patient tuple and a label.\n",
    "\n",
    "    Args:\n",
    "        line: A line from the `health-train.txt`\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple that contains a patient tuple and a label as a string\n",
    "    \"\"\"\n",
    "    assert line[-1] == \"\\n\"\n",
    "    smoker, age, diet, lable = line.strip(\"\\n\").split(\",\")\n",
    "    return (smoker, int(age), diet), lable\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('yes', 67, 'poor'), 'more')\n"
     ]
    }
   ],
   "source": [
    "def test_parse_line_train():\n",
    "    x = \"yes,67,poor,more\\n\"\n",
    "    parsed_line = parse_line_train(x)\n",
    "    print(parsed_line)\n",
    "\n",
    "    t.assertIsInstance(parsed_line, tuple)\n",
    "    t.assertEqual(len(parsed_line), 2)\n",
    "\n",
    "    data, label = parsed_line\n",
    "\n",
    "    t.assertIsInstance(data, tuple)\n",
    "    t.assertEqual(len(data), 3)\n",
    "    t.assertEqual(data[1], 67)\n",
    "\n",
    "    t.assertIsInstance(label, str)\n",
    "    t.assertNotIn(\"\\n\", label, \"Are you handling line breaks correctly?\")\n",
    "    t.assertEqual(label, \"more\")\n",
    "\n",
    "test_parse_line_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idna import decode\n",
    "\n",
    "\n",
    "def gettrain() -> list[tuple[tuple[str, int, str], str]]:\n",
    "    \"\"\"\n",
    "    Opens the `health-train.txt` file and parses it into\n",
    "    a list of patient tuples accompanied by their respective label.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples comprised of a patient tuple and a label\n",
    "    \"\"\"\n",
    "    with open(\"health-train.txt\", encoding=\"utf-8\") as f:\n",
    "        patients_info = []\n",
    "        for line in f:\n",
    "            patients_info.append(parse_line_train(line))\n",
    "    return patients_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('yes', 54, 'good'), 'less'),\n",
      " (('no', 55, 'good'), 'less'),\n",
      " (('no', 26, 'good'), 'less'),\n",
      " (('yes', 40, 'good'), 'more'),\n",
      " (('yes', 25, 'poor'), 'less'),\n",
      " (('no', 13, 'poor'), 'more'),\n",
      " (('no', 15, 'good'), 'less'),\n",
      " (('no', 50, 'poor'), 'more'),\n",
      " (('yes', 33, 'good'), 'more'),\n",
      " (('no', 35, 'good'), 'less'),\n",
      " (('no', 41, 'good'), 'less'),\n",
      " (('yes', 30, 'poor'), 'more'),\n",
      " (('no', 39, 'poor'), 'more'),\n",
      " (('no', 20, 'good'), 'less'),\n",
      " (('yes', 18, 'poor'), 'less'),\n",
      " (('yes', 55, 'good'), 'more')]\n"
     ]
    }
   ],
   "source": [
    "def test_gettrain():\n",
    "    trainset = gettrain()\n",
    "    pprint(trainset)\n",
    "    t.assertIsInstance(trainset, list)\n",
    "    t.assertEqual(len(trainset), 16)\n",
    "    first_datapoint = trainset[0]\n",
    "    t.assertIsInstance(first_datapoint, tuple)\n",
    "    t.assertIsInstance(first_datapoint[0], tuple)\n",
    "    t.assertIsInstance(first_datapoint[1], str)\n",
    "\n",
    "test_gettrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Nearest neighbor classifier\n",
    "\n",
    "We consider the nearest neighbor algorithm that classifies test points following the label of the nearest neighbor in the training data. You can read more about Nearest neighbor classifiers [here](http://www.robots.ox.ac.uk/~dclaus/digits/neighbour.htm). For this, we need to define a distance function between data points. We define it to be\n",
    "\n",
    "`distance(a, b) = (a[0] != b[0]) + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] != b[2])`\n",
    "\n",
    "where `a` and `b` are two tuples representing two patients.\n",
    "\n",
    "* Implement the distance function.\n",
    "* Implement the function that retrieves for a test point the nearest neighbor in the training set, and classifies the test point accordingly (i.e. returns the label of the nearest data point).\n",
    "\n",
    "**Hint**: You can use the special `infinity` floating point value with `float('inf')`\n",
    "\n",
    "***Keep in mind that `bool`s in Python are also `int`s. `True` is the same as `1` and `False` is the same as `0`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True + True = 2\n",
      "True + False = 1\n",
      "True * 3 = 3\n",
      "False * True = 0\n"
     ]
    }
   ],
   "source": [
    "# This cell demonstrates that boolean values can be used in arithmetic operations\n",
    "print(f'{True + True = }')\n",
    "print(f'{True + False = }')\n",
    "print(f'{True * 3 = }')\n",
    "print(f'{False * True = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a: tuple[str, int, str], b: tuple[str, int, str]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the distance between two data points (patient tuples).\n",
    "    \n",
    "    Args:\n",
    "        a, b: Two patient tuples for which we want to calculate the distance\n",
    "        \n",
    "    Returns:\n",
    "        float: The distance between a and b according to the above formula\n",
    "    \"\"\"\n",
    "    return (a[0] != b[0]) + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] != b[2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance(('yes', 34, 'poor'), ('yes', 51, 'good')) --> 1.1156\n"
     ]
    }
   ],
   "source": [
    "# Test distance\n",
    "def test_distance():\n",
    "    x1 = (\"yes\", 34, \"poor\")\n",
    "    x2 = (\"yes\", 51, \"good\")\n",
    "    dist = distance(x1, x2)\n",
    "    print(f\"distance({x1}, {x2}) --> {dist}\")\n",
    "    expected_dist = 1.1156\n",
    "    t.assertAlmostEqual(dist, expected_dist)\n",
    "\n",
    "test_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbor(x: tuple[str, int, str], trainset: list[tuple[tuple[str, int, str], str]]) -> str:\n",
    "    \"\"\"\n",
    "    Returns the label of the nearest data point in trainset to x.\n",
    "    If x is `('no', 30, 'good')` and the nearest data point in trainset\n",
    "    is `('no', 31, 'good')` with label `'less'` then `'less'` will be returned.\n",
    "    In case two elements have the exact same distance, the element that first occurs\n",
    "    in the dataset is picked (the element with the smallest index).\n",
    "\n",
    "    Args:\n",
    "        x: The data point for which we want to find the nearest neighbor\n",
    "        trainset: A list of tuples with patient tuples and a label\n",
    "\n",
    "    Returns:\n",
    "        str: The label of the nearest data point in the trainset. Can only be 'more' or 'less'.\n",
    "    \"\"\"\n",
    "    n_dist = distance(x, trainset[0][0])\n",
    "    n_lable = trainset[0][1]\n",
    "    for patient_info, lable in trainset[1:]:\n",
    "        d = distance(x, patient_info)\n",
    "        if d < n_dist:\n",
    "            n_dist = d\n",
    "            n_lable = lable\n",
    "    return n_lable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction --> more\n"
     ]
    }
   ],
   "source": [
    "# Test neighbor\n",
    "def test_neighbor():\n",
    "    x = (\"yes\", 31, \"good\")\n",
    "    prediction = neighbor(x, gettrain())\n",
    "    print(f\"prediction --> {prediction}\")\n",
    "    t.assertIn(prediction, [\"more\", \"less\"])\n",
    "    expected = \"more\"\n",
    "    t.assertEqual(prediction, expected)\n",
    "\n",
    "test_neighbor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we want to compare the decision tree we have implemented with the nearest neighbor method. Apply both the decision tree and nearest neighbor classifiers on the test set, and return the list of datapoint(s) for which the two classifiers disagree, and the probability that they disagree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (from matplotlib) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zohre\\onedrive\\desktop\\uni\\githubprojects\\deep_learning_exercise\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_classifiers(trainset: list[tuple[tuple[str, int, str], str]],\n",
    "                        testset: list[tuple[str, int, str]]) -> tuple[list[tuple[str, int, str]], float]:\n",
    "    \"\"\"\n",
    "    This function compares the two classification methods (decision tree, nearest neighbor)\n",
    "    by finding all the data points for which the methods disagree. It returns\n",
    "    a list of the test data points for which the two methods do not return\n",
    "    the same label as well as the ratio of those data points compared to the whole\n",
    "    test set (i.e. the probability of disagreement between the two methods).\n",
    "\n",
    "    Args:\n",
    "        trainset: The training set used by the nearest neighbor classifier.\n",
    "        testset: Contains the elements which will be used to compare the decision tree\n",
    "                 and nearest neighbor classification methods.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple of disagree and percentage:\n",
    "               disagree: A list containing all the data points which yield different results for the two\n",
    "                         classification methods\n",
    "               percentage: The ratio of data points for which the two methods disagree, it must be a value between 0 and 1\n",
    "    \"\"\"\n",
    "\n",
    "# decision(x: tuple[str, int, str]) -> str\n",
    "# neighbor(x: tuple[str, int, str], trainset: list[tuple[tuple[str, int, str], str]]) -> str\n",
    "    disagree=[]\n",
    "    for item in testset:\n",
    "        lbl = decision(item)\n",
    "        if neighbor(item, trainset) != lbl:\n",
    "            disagree.append(item)\n",
    "    percentage = len(disagree)/len(testset)\n",
    "    return disagree, percentage\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio = 0.125\n"
     ]
    }
   ],
   "source": [
    "# Test compare_classifiers\n",
    "def test_compare_classifiers():\n",
    "    disagree, ratio = compare_classifiers(gettrain(), gettest())\n",
    "    print(f\"ratio = {ratio}\")\n",
    "    t.assertIsInstance(disagree, list)\n",
    "    t.assertIsInstance(ratio, float)\n",
    "    t.assertIsInstance(disagree[0], tuple)\n",
    "    t.assertEqual(len(disagree[0]), 3)\n",
    "    assert_percentage(ratio)\n",
    "    t.assertTrue(0.1 < ratio < 0.2)\n",
    "\n",
    "test_compare_classifiers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem of simple nearest neighbors is that one needs to compare the point to all data points in the training set to make the prediction. This can be slow for datasets of thousands of points or more. Alternatively, some classifiers train a model first and then use it to classify the data.\n",
    "\n",
    "## 6. Nearest mean classifier\n",
    "\n",
    "We consider one such trainable model, which operates in two steps:\n",
    "\n",
    "1. Compute the average point for each class\n",
    "2. Classify new points to be of the class whose average point is nearest to the point to predict.\n",
    "\n",
    "For this classifier, we convert the attributes smoker and diet to real values (for smoker: `1.0` if 'yes' otherwise `0.0`, and for diet: `0.0` if 'good' otherwise `1.0`), and use the modified distance function:\n",
    "\n",
    "`distance(a,b) = (a[0] - b[0]) ** 2 + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] - b[2]) ** 2`\n",
    "\n",
    "Age will also from now on be represented as a `float`. The new data points will be referred to as numerical patient tuples. \n",
    "\n",
    "We adopt an object-oriented approach for building this classifier.\n",
    "\n",
    "* Implement the `gettrain_num` function that will load the training dataset from the `health-train.txt` file and parse each line to a numerical patient tuple with its label. You can still follow the same structure that we used before (i.e. using a `parse_line_...` function), however, it is not required for this exercise. Only the `gettrain_num` function will be tested.\n",
    "\n",
    "\n",
    "* Implement the new distance function.\n",
    "\n",
    "\n",
    "* Implement the methods `train` and `predict` of the class `NearestMeanClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line_train_num(line: str) -> tuple[tuple[float, float, float], str]:\n",
    "    \"\"\"\n",
    "    Takes a line from the file `health-train.txt`, including a newline,\n",
    "    and parses it into a numerical patient tuple.\n",
    "\n",
    "    Args:\n",
    "        line: A line from the `health-test.txt` file\n",
    "    Returns:\n",
    "        tuple: A numerical patient tuple and its label\n",
    "    \"\"\"\n",
    "\n",
    "    smoker, age, diet, lable = line.strip(\"\\n\").split(\",\")\n",
    "    s = 1.0 if smoker==\"yes\" else 0.0\n",
    "    a = float(age)\n",
    "    d = 0.0 if diet==\"good\" else 1.0\n",
    "    return (s, a, d), lable\n",
    "\n",
    "\n",
    "def gettrain_num() -> list[tuple[tuple[float, float, float], str]]:\n",
    "    \"\"\"\n",
    "    Parses the `health-train.txt` file into numerical patient tuples.\n",
    "\n",
    "    Returns:\n",
    "        patient_tuples: A list of tuples containing numerical patient tuples and their labels\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    with open(\"health-train.txt\", encoding=\"utf-8\") as f:\n",
    "        return [parse_line_train_num(line) for line in f]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m     t.assertIsInstance(first_datapoint[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m], \u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     10\u001b[39m     t.assertIsInstance(first_datapoint[\u001b[32m0\u001b[39m][\u001b[32m2\u001b[39m], \u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mtest_gettrain_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtest_gettrain_num\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_gettrain_num\u001b[39m():\n\u001b[32m      3\u001b[39m     trainset_num = gettrain_num()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mt\u001b[49m.assertIsInstance(trainset_num, \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m      5\u001b[39m     first_datapoint = trainset_num[\u001b[32m0\u001b[39m]\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfirst_datapoint --> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_datapoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "# Test gettrain_num\n",
    "def test_gettrain_num():\n",
    "    trainset_num = gettrain_num()\n",
    "    t.assertIsInstance(trainset_num, list)\n",
    "    first_datapoint = trainset_num[0]\n",
    "    print(f\"first_datapoint --> {first_datapoint}\")\n",
    "    t.assertIsInstance(first_datapoint[0], tuple)\n",
    "    t.assertIsInstance(first_datapoint[0][0], float)\n",
    "    t.assertIsInstance(first_datapoint[0][1], float)\n",
    "    t.assertIsInstance(first_datapoint[0][2], float)\n",
    "\n",
    "test_gettrain_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_num(a: tuple[float, float, float],\n",
    "                 b: tuple[float, float, float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the distance between two numerical patient tuples.\n",
    "    \n",
    "    Args:\n",
    "        a, b: Two numerical patient tuples for which we want to calculate the distance\n",
    "        \n",
    "    Returns:\n",
    "        float: The distance between a, b\n",
    "    \"\"\"\n",
    "    result = (a[0] - b[0]) ** 2 + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] - b[2]) ** 2\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1296\n",
      "dist --> 2.1296\n"
     ]
    }
   ],
   "source": [
    "def test_distance_num():\n",
    "    x1 = (1.0, 23.0, 0.0)\n",
    "    x2 = (0.0, 41.0, 1.0)\n",
    "    dist = distance_num(x1, x2)\n",
    "    print(f\"dist --> {dist}\")\n",
    "    t.assertIsInstance(dist, float)\n",
    "    t.assertTrue(2.12 < dist < 2.13)\n",
    "\n",
    "test_distance_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestMeanClassifier:\n",
    "    \"\"\"\n",
    "    Represents a NearestMeanClassifier.\n",
    "\n",
    "    When an instance is trained a dataset is provided and the mean for each class is calculated.\n",
    "    During prediction, the instance compares the data point to each class mean (not all data points)\n",
    "    and returns the label of the class mean to which the data point is closest to.\n",
    "\n",
    "    Instance Attributes:\n",
    "        more: A tuple representing the mean of every 'more' data point in the dataset.\n",
    "        less: A tuple representing the mean of every 'less' data point in the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.more = None\n",
    "        self.less = None\n",
    "\n",
    "    def train(self, dataset: list[tuple[tuple[float, float, float], str]]) -> \"NearestMeanClassifier\":\n",
    "        \"\"\"\n",
    "        Calculates the class means for a given dataset and stores\n",
    "        them in instance attributes `more` and `less`.\n",
    "\n",
    "        The mean of the more class is a tuple containing three elements.\n",
    "        Each element of the mean tuple contains the mean of all the elements\n",
    "        in the training set that are labeled `more` for each corresponding index.\n",
    "        This means that the mean tuple contains the mean smoker, age and health\n",
    "        values.\n",
    "        The same is true of the less mean tuple, but for all the elements\n",
    "        labeled `less`.\n",
    "\n",
    "        This function does not return anything useful, but it has the side\n",
    "        effect of setting the more and less instance variables.\n",
    "\n",
    "        Args:\n",
    "            dataset: A list of tuples each of them containing a numerical patient tuple\n",
    "                     and its label\n",
    "        Returns:\n",
    "            NearestMeanClassifier: Instance of NearestMeanClassifier class\n",
    "        \"\"\"\n",
    "\n",
    "        moreset = (x[0] for x in dataset if x[1]==\"more\")\n",
    "        lessset = (x[0] for x in dataset if x[1]==\"less\")\n",
    "\n",
    "        self.more = tuple(sum(attr) / len(attr) for attr in zip(*moreset))\n",
    "        self.less = tuple(sum(attr) / len(attr) for attr in zip(*lessset))\n",
    "        \"\"\"\n",
    "        Why we use zip?\n",
    "        groups the first elements of all â€œmoreâ€ tuples together, then the second elements together, then the third, so you can sum each dimension separately (smoker, age, health).\n",
    "\n",
    "        \n",
    "        Why *moreset?\n",
    "        it unpacks the elements\n",
    "\n",
    "\n",
    "        why tuple?\n",
    "        cause we want it immutable, fixed length\n",
    "        \"\"\"\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x: tuple[float, float, float]) -> str:\n",
    "        \"\"\"\n",
    "        Returns a prediction/label for numeric patient tuple x.\n",
    "        The classifier compares the given data point to the mean\n",
    "        class tuples of each class and returns the label of the\n",
    "        class to which x is the closest to (according to our\n",
    "        distance function). In the unlikely case that the distance\n",
    "        is equal for both classes, then `'less'` is returned.\n",
    "\n",
    "        Args:\n",
    "            x: A numerical patient tuple for which we want a prediction\n",
    "            \n",
    "        Returns:\n",
    "            str: The predicted label\n",
    "        \"\"\"\n",
    "\n",
    "        if distance_num(x, self.less) <= distance_num(x, self.more):\n",
    "            return \"less\"\n",
    "        return \"more\"\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        try:\n",
    "            more = tuple(round(m, 3) for m in self.more)\n",
    "            less = tuple(round(l, 3) for l in self.less)\n",
    "        except AttributeError:\n",
    "            more, less = None, None\n",
    "        return f\"{self.__class__.__name__}(more: {more}, less: {less})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing all three classification methods\n",
    "Finally, we want to compare all three methods that we have implemented. Similarly to how we needed to define a new method to load the training data for the nearest mean classifier, we need to define an equivalent method to load the test data. Our goal is to see for which data points all three classifiers output the same result.\n",
    "\n",
    "* Load the test dataset into memory as a list of numerical patient tuples. In order to achieve this you have to implement the `gettest_num` function.\n",
    "* Apply all three methods on each datapoint in the testset and return the index of all test examples for which all three classifiers (decision tree, nearest neighbor and nearest mean) agree. Remember that for the nearest mean method we used an OOP approach, so you will have to create an instance and train the model in order to be able to use it on the test data.\n",
    "\n",
    "**Note**: Be careful that the `NearestMeanClassifier` expects the dataset in a different form, compared to the other two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gettest_num() -> list[tuple[float, float, float]]:\n",
    "    \"\"\"\n",
    "    Parses the `health-test.txt` file into numerical patient tuples.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing numerical patient tuples (tuples consisting of 3 floats), loaded from `health-test.txt`\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    with open(\"health-test.txt\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            smoker, age, diet = line.strip().split(\",\")\n",
    "            s = 1.0 if smoker==\"yes\" else 0.0\n",
    "            a = float(age)\n",
    "            d = 0.0 if diet==\"good\" else 1.0\n",
    "            result.append((s, a, d))\n",
    "    return result \n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pprint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     t.assertEqual(\u001b[38;5;28mlen\u001b[39m(testset_num[\u001b[32m0\u001b[39m]), \u001b[32m3\u001b[39m)\n\u001b[32m      8\u001b[39m     t.assertEqual(testset_num[\u001b[32m0\u001b[39m], (\u001b[32m1.0\u001b[39m, \u001b[32m21.0\u001b[39m, \u001b[32m1.0\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtest_gettest_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mtest_gettest_num\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_gettest_num\u001b[39m():\n\u001b[32m      2\u001b[39m     testset_num = gettest_num()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mpprint\u001b[49m(testset_num)\n\u001b[32m      4\u001b[39m     t.assertIsInstance(testset_num, \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m      5\u001b[39m     t.assertEqual(\u001b[38;5;28mlen\u001b[39m(testset_num), \u001b[32m8\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pprint' is not defined"
     ]
    }
   ],
   "source": [
    "def test_gettest_num():\n",
    "    testset_num = gettest_num()\n",
    "    pprint(testset_num)\n",
    "    t.assertIsInstance(testset_num, list)\n",
    "    t.assertEqual(len(testset_num), 8)\n",
    "    t.assertIsInstance(testset_num[0], tuple)\n",
    "    t.assertEqual(len(testset_num[0]), 3)\n",
    "    t.assertEqual(testset_num[0], (1.0, 21.0, 1.0))\n",
    "\n",
    "test_gettest_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test() -> list:\n",
    "    \"\"\"\n",
    "    Classifies the test set using all the methods that were developed in this exercise sheet,\n",
    "    namely `decision`, `neighbor` and `NearestMeanClassifier`.\n",
    "    This function loads all the needed data by calling the corresponding functions\n",
    "    (gettrain, gettest, gettrain_num, gettest_num).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of the indices of all the data points for which all three classifiers have\n",
    "              the same output\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test = gettrain(), gettest()\n",
    "    X_num_train, X_num_test = gettrain_num(), gettest_num()\n",
    "\n",
    "    classifier = NearestMeanClassifier().train(X_num_train)\n",
    "\n",
    "    DT = (decision(x) for x in X_test)\n",
    "    NN = (neighbor(x, X_train) for x in X_test)\n",
    "    NM = (classifier.predict(x) for x in X_num_test)\n",
    "\n",
    "    agreed_samples = [\n",
    "        i for i, (dt, nn, nm) in enumerate(zip(DT, NN, NM)) if dt == nn == nm\n",
    "    ]\n",
    "\n",
    "    return agreed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gettrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     t.assertIsInstance(same_predictions[\u001b[32m0\u001b[39m], \u001b[38;5;28mint\u001b[39m)\n\u001b[32m      7\u001b[39m     t.assertEqual(same_predictions[-\u001b[32m2\u001b[39m:], [\u001b[32m6\u001b[39m, \u001b[32m7\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtest_predict_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mtest_predict_test\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_predict_test\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     same_predictions = \u001b[43mpredict_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     pprint(same_predictions)\n\u001b[32m      4\u001b[39m     t.assertIsInstance(same_predictions, \u001b[38;5;28mlist\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mpredict_test\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_test\u001b[39m() -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Classifies the test set using all the methods that were developed in this exercise sheet,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    namely `decision`, `neighbor` and `NearestMeanClassifier`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[33;03m              the same output\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     X_train, X_test = \u001b[43mgettrain\u001b[49m(), gettest()\n\u001b[32m     14\u001b[39m     X_num_train, X_num_test = gettrain_num(), gettest_num()\n\u001b[32m     16\u001b[39m     classifier = NearestMeanClassifier().train(X_num_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'gettrain' is not defined"
     ]
    }
   ],
   "source": [
    "def test_predict_test():\n",
    "    same_predictions = predict_test()\n",
    "    pprint(same_predictions)\n",
    "    t.assertIsInstance(same_predictions, list)\n",
    "    t.assertEqual(len(same_predictions), 6)\n",
    "    t.assertIsInstance(same_predictions[0], int)\n",
    "    t.assertEqual(same_predictions[-2:], [6, 7])\n",
    "\n",
    "test_predict_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Results\n",
    "\n",
    "Often when working with a machine learning model we will want to save the classifications made by the model for further analysis. In this case, where we have few data points in the test set and our models are fairly simple, we can easily run the model again and less than a second later we have our results, however in practice this is usually not the case. \n",
    "\n",
    "We will save the classifications made by all three models in a `csv` file, or comma-separated file, `health-test-results.csv`. A `csv` file has two components, the header, and the data. Each line in a `csv` file contains the same number of values which are separated by commas. The header provides a label for the value of each position in each line, and usually indicates something about what these values mean.\n",
    "\n",
    "To do this we will create a `csv` file with the header:\n",
    "\n",
    "`smoker,age,diet,pred_decision_tree,pred_nearest_neighbor,pred_nearest_mean`\n",
    "\n",
    "We will do this in three steps:\n",
    "\n",
    "1) Write the function `to_csv` that takes `header` as a fixed argument, and an arbitrary number of arguments afterwards, which should be the data for each column defined in the header. Be sure to check that the number of entries in the header is the same as the number of arbitrary elements passed to the function. The arbitrary elements passed to the function are lists of values for each column, and as such, they should all be the same length. Raise a `ValueError` if either of these are not the case.\n",
    "\n",
    "2) Write the function `safe_write` that writes a string to a file. This function should check to see if there already exists a file of the same name and that the name of the output file ends with `.csv`. If the file already exists, raise a `RuntimeError`. If the file name does not end in `.csv`, raise a `ValueError`. Be sure to combine the folder and output file for the full file path.\n",
    "\n",
    "3) Write the function `save_results` that classifies all samples in the test set with each classifier, as is done in `predict_test`, creates a `csv` with `to_csv`, and writes the results to a file using `safe_write`.\n",
    "\n",
    "Call `save_results` at the end of the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def to_csv(header: list[str], *args) -> str:\n",
    "    \n",
    "\n",
    "### Please enter your solution here ###\n",
    "\n",
    "\n",
    "\n",
    "def safe_write(text_data: str, outfile='output.csv', folder='./'):\n",
    "    \n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "\n",
    "### Please enter your solution here ###\n",
    "\n",
    "\n",
    "\n",
    "def save_results() -> None:\n",
    "\n",
    "    header = [\"smoker\", \"age\", \"diet\", \"pred_decision_tree\", \"pred_nearest_neighbor\", \"pred_nearest_mean\"]\n",
    "    \n",
    "\n",
    "### Please enter your solution here ###\n",
    "\n",
    "    \n",
    "\n",
    "save_results()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python (.venv deep_learning)",
   "language": "python",
   "name": "deep_learning_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
